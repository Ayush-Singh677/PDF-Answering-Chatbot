
# Smart Querying for PDFs

## Introduction

This application provides a interface for querying a pdf file smartly .It performs detailed text extraction from pdf using tessaract and preprocessing, including text cleaning and segmentation into manageable chunks. These chunks are embedded using the sentence-transformers/all-mpnet-base-v2 model and stored in a FAISS vector database for efficient similarity searches. Users can input queries related to the PDF content, with responses generated by the t5-large model, which synthesizes information from relevant text chunks to deliver precise answers. 

## Project Flow
![alt text](assets/image.png)

### 1. Extracting the text from pdf files

## 1. Convert PDF to Images

1.	Convert PDF Pages to Images:
First, we take the PDF file and convert each of its pages into images. This is done because PDFs are composed of text and graphics that we need to interpret as images for further processing. This step involves reading the entire PDF file and generating an image for each page.
2.	Prepare Images for Text Extraction:
Once we have the images of the PDF pages, the next step is to enhance these images to make it easier for OCR to accurately recognize the text. To do this, we convert the images into grayscale. Grayscale images help simplify the data by removing color information, which can reduce noise and focus on the text.
After converting to grayscale, we apply a technique called thresholding. This technique transforms the grayscale image into a binary image where the text appears in high contrast against the background. This makes the text more distinct and easier for OCR to detect.
3.	Perform Optical Character Recognition (OCR):
With the preprocessed images ready, we use OCR technology to read and extract the text from each image. OCR works by analyzing the patterns in the image and converting them into readable text. The OCR engine examines the binary image and identifies characters and words.
4.	Combine Text from All Pages:
After extracting text from each image, we compile the text from all pages into a single cohesive text. This means that if the PDF has multiple pages, the text extracted from each page is collected and combined into one large text block, maintaining the content and flow of the original document.


## Setup

Ensure you have latest version of python installed (python=3.9.19).

1. Install all the required libraries.
```
pip install -r requirements.txt
```

2. Download all the required models.
```
python3 download_models.py
```

3. Run the streamlit app.
```
streamlit run app.py
```
4. Upload the pdf file and ask your question.


   ![alt text](assets/frontend.png)
## Resources 
```google-t5/t5-large``` - <a href="https://huggingface.co/google-t5/t5-large">Hugging Face<a/> <br>
```sentence-transformers/all-mpnet-base-v2``` - <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2">Hugging Face<a/>
